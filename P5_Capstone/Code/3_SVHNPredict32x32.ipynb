{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kR-4eNdK6lYS"
   },
   "source": [
    "Deep Learning Final Project\n",
    "=============\n",
    "\n",
    "# ยง3 Making Predictions on the remaining MNIST Style Greyscale Data\n",
    "------------\n",
    "\n",
    "In a previous iPython Notebooks (`0_SVHNDownloadExtract.ipynb` and `1_SVHNExploreProcess32x32.ipynb`), we downloaded the MNIST like 32 x 32 image dataset and then processed it in preparation for model training. In `2_SVHN_TrainPredict.ipynb` we trained and evaluated the performance of a Neural Network using the data contained in the extra_32x32 dataset.\n",
    "\n",
    "Here we test the performance of this model on the datasets contained in test_32x32 and train_32x32.\n",
    "\n",
    "## 3.1 Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "JLpLa8Jt7Vu4"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import time\n",
    "from IPython.display import display, Image\n",
    "from six.moves import cPickle as pickle\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1HrCK6e17WzV"
   },
   "source": [
    "## 3.2 Reload the data we generated in `1_SVHNExploreProcess32x32.ipynb`\n",
    "Supposedly, the extra data examples are 'somewhat less difficult' we'll start with those and see how we do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 19456,
     "status": "ok",
     "timestamp": 1449847956073,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "y3-cj1bpmuxc",
    "outputId": "0ddb1607-1fc4-4ddb-de28-6c7ab7fb0c33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extra_32x32 set 1:  (177043, 32, 32) (177043,)\n",
      "\n",
      "train_32x32 set: (73257, 32, 32) (73257,)\n",
      "\n",
      "test_32x32 set: (26032, 32, 32) (26032,)\n"
     ]
    }
   ],
   "source": [
    "# Stick all the data into train_dataset and train_labels\n",
    "\n",
    "with open('data/32x32/greyscale/gs_extra1.pickle', 'rb') as f:\n",
    "    save = pickle.load(f)\n",
    "    extra_dataset = save['data']\n",
    "    extra_labels = save['labels']\n",
    "    del save  # hint to help gc free up memory\n",
    "    print('extra_32x32 set 1: ', extra_dataset.shape, extra_labels.shape)\n",
    "print('')\n",
    "\n",
    "with open('data/32x32/greyscale/gs_train.pickle', 'rb') as f:\n",
    "    save = pickle.load(f)\n",
    "    train_32x32_dataset = save['data']\n",
    "    train_32x32_labels = save['labels']\n",
    "    del save  # hint to help gc free up memory\n",
    "    print('train_32x32 set:', train_32x32_dataset.shape, train_32x32_labels.shape)\n",
    "print('')\n",
    "\n",
    "with open('data/32x32/greyscale/gs_test.pickle', 'rb') as f:\n",
    "    save = pickle.load(f)\n",
    "    test_32x32_dataset = save['data']\n",
    "    test_32x32_labels = save['labels']\n",
    "    del save  # hint to help gc free up memory\n",
    "    print('test_32x32 set:', test_32x32_dataset.shape, test_32x32_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set: (26556, 32, 32) (26556,)\n",
      "valid set: (26556, 32, 32) (26556,)\n",
      "test_32x32 set: (26032, 32, 32) (26032,)\n",
      "train_32x32 set: (73257, 32, 32) (73257,)\n"
     ]
    }
   ],
   "source": [
    "# Get the data we used to validation and testing when training our model\n",
    "\n",
    "split_index = 26556\n",
    "test_dataset,  test_labels  = extra_dataset[           :  split_index,:,:], extra_labels[           :  split_index]\n",
    "valid_dataset, valid_labels = extra_dataset[split_index:2*split_index,:,:], extra_labels[split_index:2*split_index]\n",
    "del extra_dataset, extra_labels\n",
    "\n",
    "print('test set:', test_dataset.shape, test_labels.shape)\n",
    "print('valid set:', valid_dataset.shape, test_labels.shape)\n",
    "\n",
    "print('test_32x32 set:', test_32x32_dataset.shape, test_32x32_labels.shape)\n",
    "print('train_32x32 set:', train_32x32_dataset.shape, train_32x32_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set: (26556, 1024) (26556, 10)\n",
      "valid set: (26556, 1024) (26556, 10)\n",
      "test_32x32 set: (26032, 1024) (26032, 10)\n",
      "train_32x32 set: (73257, 1024) (73257, 10)\n"
     ]
    }
   ],
   "source": [
    "image_size = 32\n",
    "num_labels = 10\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "    dataset = dataset.reshape((-1, image_size * image_size)).astype(np.float32)\n",
    "    labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "    return dataset, labels\n",
    "\n",
    "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "\n",
    "test_32x32_dataset, test_32x32_labels = reformat(test_32x32_dataset, test_32x32_labels)\n",
    "train_32x32_dataset, train_32x32_labels = reformat(train_32x32_dataset, train_32x32_labels)\n",
    "\n",
    "print('test set:', test_dataset.shape, test_labels.shape)\n",
    "print('valid set:', valid_dataset.shape, test_labels.shape)\n",
    "\n",
    "print('test_32x32 set:', test_32x32_dataset.shape, test_32x32_labels.shape)\n",
    "print('train_32x32 set:', train_32x32_dataset.shape, train_32x32_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3.3 Reload the model we saved in `2_SVHNTrainPredict32x32.ipynb` and make predictions\n",
    "\n",
    "We make predictions on our training and test sets to check we've loaded our model correctly and get the accuracy we found when training. We then make predictions on the additional datasets provided train_32x32 and test_32x32 to see how robust our model is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1)) / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test/valid: 0 of 207 time =  1.46046996117 test acc: 92.1875 valid acc: 86.71875\n",
      "test/valid: 10 of 207 time =  23.5634129047 test acc: 88.28125 valid acc: 92.96875\n",
      "test/valid: 20 of 207 time =  31.1093809605 test acc: 89.0625 valid acc: 90.625\n",
      "test/valid: 30 of 207 time =  45.319892168 test acc: 93.75 valid acc: 93.75\n",
      "test/valid: 40 of 207 time =  54.4379329681 test acc: 93.75 valid acc: 92.96875\n",
      "test/valid: 50 of 207 time =  60.6018929482 test acc: 89.0625 valid acc: 95.3125\n",
      "test/valid: 60 of 207 time =  70.2755680084 test acc: 91.40625 valid acc: 94.53125\n",
      "test/valid: 70 of 207 time =  87.3022480011 test acc: 96.875 valid acc: 91.40625\n",
      "test/valid: 80 of 207 time =  102.139631987 test acc: 90.625 valid acc: 95.3125\n",
      "test/valid: 90 of 207 time =  110.696629047 test acc: 89.84375 valid acc: 92.96875\n",
      "test/valid: 100 of 207 time =  130.845287085 test acc: 91.40625 valid acc: 94.53125\n",
      "test/valid: 110 of 207 time =  127.133752823 test acc: 96.09375 valid acc: 92.96875\n",
      "test/valid: 120 of 207 time =  124.60206008 test acc: 91.40625 valid acc: 94.53125\n",
      "test/valid: 130 of 207 time =  168.63993001 test acc: 91.40625 valid acc: 94.53125\n",
      "test/valid: 140 of 207 time =  222.613790035 test acc: 94.53125 valid acc: 94.53125\n",
      "test/valid: 150 of 207 time =  376.738029003 test acc: 95.3125 valid acc: 96.09375\n",
      "test/valid: 160 of 207 time =  466.535205841 test acc: 93.75 valid acc: 95.3125\n",
      "test/valid: 170 of 207 time =  550.43403101 test acc: 86.71875 valid acc: 89.0625\n",
      "test/valid: 180 of 207 time =  537.280761003 test acc: 96.09375 valid acc: 92.96875\n",
      "test/valid: 190 of 207 time =  559.924669981 test acc: 91.40625 valid acc: 95.3125\n",
      "test/valid: 200 of 207 time =  593.305698156 test acc: 91.40625 valid acc: 93.75\n",
      "valid_accuracy =  93.0857487923\n",
      "test_accuracy =  93.0442330918\n",
      "test_32x32: 0 of 203 time =  31.2313008308 test acc: 86.71875\n",
      "test_32x32: 10 of 203 time =  333.38025403 test acc: 85.15625\n",
      "test_32x32: 20 of 203 time =  358.011176109 test acc: 85.9375\n",
      "test_32x32: 30 of 203 time =  378.280328035 test acc: 87.5\n",
      "test_32x32: 40 of 203 time =  470.778951883 test acc: 85.15625\n",
      "test_32x32: 50 of 203 time =  442.30705595 test acc: 84.375\n",
      "test_32x32: 60 of 203 time =  485.643501043 test acc: 87.5\n",
      "test_32x32: 70 of 203 time =  518.392277002 test acc: 85.9375\n",
      "test_32x32: 80 of 203 time =  546.853780985 test acc: 87.5\n",
      "test_32x32: 90 of 203 time =  535.461681128 test acc: 86.71875\n",
      "test_32x32: 100 of 203 time =  542.390861988 test acc: 85.15625\n",
      "test_32x32: 110 of 203 time =  533.566871881 test acc: 80.46875\n",
      "test_32x32: 120 of 203 time =  562.743112087 test acc: 90.625\n",
      "test_32x32: 130 of 203 time =  581.325016975 test acc: 83.59375\n",
      "test_32x32: 140 of 203 time =  608.419938087 test acc: 90.625\n",
      "test_32x32: 150 of 203 time =  675.259671926 test acc: 85.9375\n",
      "test_32x32: 160 of 203 time =  667.916843891 test acc: 78.90625\n",
      "test_32x32: 170 of 203 time =  710.203726053 test acc: 89.84375\n",
      "test_32x32: 180 of 203 time =  819.885910034 test acc: 85.15625\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-8d5003f4fe7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mtest_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_32x32_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_prediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_32x32_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0msum_test_accuracy\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtest_accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-8d5003f4fe7b>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     18\u001b[0m                              tf.matmul(data, h1_weights) + h1_biases),\n\u001b[1;32m     19\u001b[0m                                              h2_weights) + h2_biases),\n\u001b[0;32m---> 20\u001b[0;31m                                                 weights) + biases).eval()\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0msum_test_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m     \"\"\"\n\u001b[0;32m--> 559\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   3759\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3760\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 3761\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 717\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    718\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 915\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    916\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 965\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    970\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    973\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    952\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m    953\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "with tf.Session() as session:\n",
    "\n",
    "    new_saver = tf.train.import_meta_graph('3Layer32x32Model.meta')\n",
    "    new_saver.restore(session, tf.train.latest_checkpoint('./'))\n",
    "\n",
    "    h1_weights = session.run(tf.get_collection('h1w')[0])\n",
    "    h1_biases  = session.run(tf.get_collection('h1b')[0])\n",
    "    h2_weights = session.run(tf.get_collection('h2w')[0])\n",
    "    h2_biases  = session.run(tf.get_collection('h2b')[0])\n",
    "    weights    = session.run(tf.get_collection('w'  )[0])\n",
    "    biases     = session.run(tf.get_collection('b'  )[0])\n",
    "\n",
    "    def predict(data):\n",
    "        return tf.nn.softmax(tf.matmul(tf.nn.relu(\n",
    "                             tf.matmul(tf.nn.relu(\n",
    "                             tf.matmul(data, h1_weights) + h1_biases),\n",
    "                                             h2_weights) + h2_biases),\n",
    "                                                weights) + biases).eval()\n",
    "\n",
    "    sum_test_accuracy = 0\n",
    "    sum_valid_accuracy = 0\n",
    "    num_batches = test_labels.shape[0] // batch_size\n",
    "    t1 = time.time()\n",
    "    for i in xrange(num_batches):\n",
    "        test_prediction = predict(test_dataset[i*batch_size:(i+1)*batch_size, :])\n",
    "        test_accuracy = accuracy(test_prediction, test_labels[i*batch_size:(i+1)*batch_size, :])\n",
    "        sum_test_accuracy += test_accuracy\n",
    "        valid_prediction = predict(valid_dataset[i*batch_size:(i+1)*batch_size, :])\n",
    "        valid_accuracy = accuracy(valid_prediction, valid_labels[i*batch_size:(i+1)*batch_size, :])\n",
    "        sum_valid_accuracy += valid_accuracy\n",
    "        if i%10==0:\n",
    "            t2 = time.time()\n",
    "            print('test/valid:', i, 'of', num_batches, 'time = ', t2-t1, 'test acc:', test_accuracy,\n",
    "                                                                         'valid acc:', valid_accuracy)\n",
    "            t1 = t2\n",
    "    print('valid_accuracy = ', sum_valid_accuracy/num_batches)\n",
    "    print('test_accuracy = ' , sum_test_accuracy/num_batches)\n",
    "\n",
    "    sum_test_accuracy = 0\n",
    "    num_batches = test_32x32_labels.shape[0] // batch_size\n",
    "    t1 = time.time()\n",
    "    for i in xrange(num_batches):\n",
    "        test_prediction = predict(test_32x32_dataset[i*batch_size:(i+1)*batch_size, :])\n",
    "        test_accuracy = accuracy(test_prediction, test_32x32_labels[i*batch_size:(i+1)*batch_size, :])\n",
    "        sum_test_accuracy += test_accuracy\n",
    "        if i%10==0:\n",
    "            t2 = time.time()\n",
    "            print('test_32x32:', i, 'of', num_batches, 'time = ', t2-t1, 'test acc:', test_accuracy)\n",
    "            t1 = t2\n",
    "    print('test_32x32_accuracy = ' , sum_test_accuracy/num_batches)\n",
    "\n",
    "    sum_train_accuracy = 0\n",
    "    num_batches = train_32x32_labels.shape[0] // batch_size\n",
    "    for i in xrange(num_batches):\n",
    "        train_prediction = predict(train_32x32_dataset[i*batch_size:(i+1)*batch_size, :])\n",
    "        train_accuracy = accuracy(train_prediction, train_32x32_labels[i*batch_size:(i+1)*batch_size, :])\n",
    "        sum_train_accuracy += train_accuracy\n",
    "        if i%10==0:\n",
    "            t2 = time.time()\n",
    "            print('train_32x32:', i, 'of', num_batches, 'time = ', t2-t1, 'train acc:', train_accuracy)\n",
    "            t1 = t2\n",
    "    print('train_32x32_accuracy = ' , sum_train_accuracy/num_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "default_view": {},
   "name": "2_fullyconnected.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
